---
layout: default
title: Efficiency, Security, and Generalization of Multimedia Foundation Models
description: Workshop @ ACM Multimedia 2024
---

**Welcome to The 1st Workshop on Efficiency, Security, and Generalization of Multimedia Foundation Models at ACM Multimedia 2024!**

---

## **Call for Papers** {#call}

**Submission Deadline: <strike>July 19, 2024</strike> <span>Extended to July 29</span>**

**Submit Platform: [OpenReview](https://openreview.net/group?id=acmmm.org/ACMMM/2024/Workshop/ESGMFM)**


The rapid progress in foundation models has enhanced the capabilities of multimedia models across a broad spectrum of tasks. Despite their exceptional performance, deploying these models in practical settings raises several concerns, particularly regarding efficiency, security, and generalization. As the utility of foundation models in multimedia topics becomes increasingly evident, addressing these issues is crucial. This workshop focuses on these critical aspects in foundation models, where the scope of the foundation model encompasses a wide range of domains such as vision, language, speech etc., with an emphasis on multimedia tasks and multi-modality methods. 

Therefore, we solicit original research papers in (but not limited to) the following topics:

**Efficiency**
- Efficient network design in foundation models
- Training efficiency of foundation models
- Inference efficiency of foundation models

**Security**
- Adversarial robustness of foundation models
- Privacy and memorization in foundation models
- Trustworthiness and alignment of foundation models

**Generalization**
- Generalization across tasks
- Generalization across data
- Generalization across modalities


We also welcome submissions of demos, datasets, and position papers within the workshop's scopes.
The submission guideline follows the main conference site of [ACM Multimedia 2024](https://2024.acmmm.org/), including the formatting guideline and submission policies. 
The review process for this workshop will be "double-blinded‚Äù.
Submissions should be of up to 4-page length in [ACM-MM format](https://2024.acmmm.org/files/ACM-MM24-paper-templates.zip), plus up to 1 additional page for the references.

All papers will be peer-reviewed by at least three experts in the field, regarding the relevance to the workshop, scientific novelty, and technical quality. 
Accepted submissions will be presented via oral or poster sessions. 
All accepted papers will be published in the **ACM Multimedia proceedings** in the ACM Digital Library.
We will select from the accepted papers the **Best Paper Award**, which will be announced during the workshop.

Submit your manuscripts through [OpenReview](https://openreview.net/group?id=acmmm.org/ACMMM/2024/Workshop/ESGMFM).
All the authors need to create a profile on OpenReview. 
New profiles created without an institutional email will go through a moderation process that can take up to two weeks. 
New profiles created with an institutional email will be activated automatically.

---
## **Important Dates** {#dates}

| Submission Open | **May 11, 2024 (AoE)** |
| Submission Deadline | **<strike>July 19, 2024</strike> <span>Extended to July 29 (AoE)</span>** |
| Decision Notification | **August 5, 2024 (AoE)** |
| Camera-Ready Deadline | **August 19, 2024 (AoE)** |
| Workshop Date | **Oct 28 PM, 2024** |

---

## **Schedule** {#schedule}

The following schedule is tentative and will be confirmed closer to the workshop:



|   **Time**  |         **Topic**        |                             **Speakers**                            |
|------------:|:-------------------------|:-----------------------------------------------------------------------------------|
| 13:30 | *Start*                                |                                   |
| 13:30 | Opening Remarks                        | TBD                               |
| 13:40 | Invited Talk 1                         | TBD                               |
| 14:10 | Invited Talk 2                         | TBD                               |
| 14:40 | Paper Presentation 1                   | TBD                               |
| 14:55 | *Coffee Break*                         |                                   |
| 15:10 | Invited Talk 3                         | TBD                               |
| 15:40 | Industry Talk 1                        | TBD                               |
| 16:10 | Paper Presentation 2                   | TBD                               |
| 16:25 | Paper Presentation 3                   | TBD                               |
| 16:40 | Closing and Awards                     | TBD                               |
| 16:50 | *End*                                  |                                   |

---

## **Invited Speakers** {#speakers}

Coming soon

<!-- <div class="container">
    <figure>
        <a href="https://beerys.github.io/">
        <img class="img-author" src="assets/imgs/authors/cvpr2024/SaraBeery.jpeg" alt="Sara Beery"/></a>
        <b><br><a href="https://sites.google.com/cs.washington.edu/william-agnew/home">Sara Beery (She/Her)</a>
        <br>Assistant Professor<br>MIT</b>
    </figure>
    <figure>
        <a href="https://sites.google.com/cs.washington.edu/william-agnew/home">
        <img class="img-author" src="assets/imgs/authors/cvpr2024/WilliamAgnew.jpeg" alt="William Agnew"/></a>
        <b><br><a href="https://sites.google.com/cs.washington.edu/william-agnew/home">William Agnew</a>
        <br>CBI Postdoc Fellow<br>CMU</b>
    </figure>
</div>

<div class="bio-text">
<a href="https://beerys.github.io/"><b>Dr. Sara Beery</b></a>
is the Homer A. Burnell Career Development Professor in the MIT Faculty of Artificial Intelligence and Decision-Making. She was previously a visiting researcher at Google, working on large-scale urban forest monitoring as part of the Auto Arborist project. She received her PhD in Computing and Mathematical Sciences at Caltech in 2022, where she was advised by Pietro Perona and awarded the Amori Doctoral Prize for her thesis. Her research focuses on building computer vision methods that enable global-scale environmental and biodiversity monitoring across data modalities, tackling real-world challenges including geospatial and temporal domain shift, learning from imperfect data, fine-grained categories, and long-tailed distributions. She partners with industry, nongovernmental organizations, and government agencies to deploy her methods in the wild worldwide. She works toward increasing the diversity and accessibility of academic research in artificial intelligence through interdisciplinary capacity building and education, and has founded the AI for Conservation slack community, serves as the Biodiversity Community Lead for Climate Change AI, and founded and directs the Summer Workshop on Computer Vision Methods for Ecology.

 -->


<!-- ---

## **Program Committee** {#Committee}

Coming soon -->

---

## **Organizers** {#organizers}
<div class="container">

<figure>
    <a href="https://daochang.site/">
    <img class="img-author" src="assets/imgs/authors/daochang_liu.jpg" alt="Daochang Liu"/></a>
    <b><br><a href="https://daochang.site/">Daochang Liu</a>
    <br>The University of Sydney</b>
</figure>

<figure>
    <a href="https://www.cs.cityu.edu.hk/~minjdong/">
    <img class="img-author" src="assets/imgs/authors/minjing_dong.png" alt="Minjing Dong"/></a>
    <b><br><a href="https://www.cs.cityu.edu.hk/~minjdong/">Minjing Dong</a>
    <br>City University of Hong Kong</b>
</figure>


<figure>
    <a href="https://research.monash.edu/en/persons/yasmeen-george">
    <img class="img-author" src="assets/imgs/authors/yasmeen_george.png" alt="Yasmeen George"/></a>
    <b><br><a href="https://research.monash.edu/en/persons/yasmeen-george">Yasmeen George</a>
    <br>Monash University</b>
</figure>


<figure>
    <a href="http://changxu.xyz/">
    <img class="img-author" src="assets/imgs/authors/chang_xu.jpeg" alt="Chang Xu"/></a>
    <b><br><a href="http://changxu.xyz/">Chang Xu</a>
    <br>The University of Sydney</b>
</figure>

</div>

---
## **Sponsors** {#sponsors}

<figure>
    <a href="https://mtlab.meitu.com/en/?lang=en">
    <img src="assets/imgs/sponsors/meitu.png" alt="Meitu"/>
    </a>
</figure>

---
## **Contact** {#contact}

Contact the organizers at [mm2024-esgmfm@googlegroups.com](mailto:mm2024-esgmfm@googlegroups.com)

<!-- ## Program Committee
## Sponsors -->

